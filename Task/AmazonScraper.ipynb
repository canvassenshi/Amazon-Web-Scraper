{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb629b37-7cb4-4d37-908c-03df89b7a6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66d23668-f556-495d-b288-0959d3dab573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0       id        Asin country\n",
      "0             0        1        1015      de\n",
      "1             1  2424796        1015      fr\n",
      "2             2        2  000004458X      de\n",
      "3             3  2424797  000004458X      fr\n",
      "4             4        3     1002198      de\n",
      "..          ...      ...         ...     ...\n",
      "995         995  2425286     4484924      fr\n",
      "996         996      449     4485742      de\n",
      "997         997  2425287     4485742      fr\n",
      "998         998      450     4486072      de\n",
      "999         999  2425288     4486072      fr\n",
      "\n",
      "[1000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#LOADING THE CSV FILE DATA\n",
    "df = pd.read_csv(\"amazon.csv\")\n",
    "print(df)\n",
    "\n",
    "urls = [] #list to store the urls\n",
    "\n",
    "for index, rows in df.iterrows():\n",
    "    URL = f\"https://www.amazon.{rows.country}/dp/{rows.Asin}\"\n",
    "    urls.append(URL)\n",
    "        \n",
    "    \n",
    "#SETTING UP BS4\n",
    "headers =  {\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.81 Safari/537.36\"}\n",
    "\n",
    "\n",
    "#FUNCTIONS TO EXTRACT DATA\n",
    "\n",
    "def get_description(soup):\n",
    "    description = soup.find(id=[\"featurebullets_feature_div\", \"bookDescription_feature_div\"]).get_text().strip()\n",
    "    return description\n",
    "\n",
    "def get_image_link(soup):\n",
    "    img_link = soup.find(id = [\"imgTagWrapperId\",\"img-canvas\"]).img[\"src\"]\n",
    "    return img_link\n",
    "    \n",
    "def get_price(soup):\n",
    "    try:\n",
    "        price = soup.find(\"span\", attrs = {\"class\" : [\"a-price\", \"a-color-price\"]}).get_text().strip() \n",
    "    except AttributeError:\n",
    "        price = \"NA\"\n",
    "    return price\n",
    "        \n",
    "def get_title(soup):\n",
    "    if page.status_code == 200: #not 404 error\n",
    "        title = soup.find(id=\"productTitle\").get_text().strip()\n",
    "        return title\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87103091-c6a2-4701-95c9-d2fa9d069e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {}\n",
    "\n",
    "i = 0\n",
    "for url in urls:\n",
    "    page = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(page.content, \"lxml\")\n",
    "    if(get_title(soup)==None):\n",
    "        pass\n",
    "    else:\n",
    "        i += 1\n",
    "        dictionary[i] = [url, get_title(soup), get_price(soup), get_image_link(soup), get_description(soup)]\n",
    "\n",
    "with open('output.json', 'w') as json_file:\n",
    "  json.dump(dictionary, json_file, indent = 4)\n",
    "       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fbda4b11-8d7c-4949-b1ca-e0a4c1a3606d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old Spice Rasur Creme - 70 G (original) - Packung Von 2\n"
     ]
    }
   ],
   "source": [
    "#Reading the output json file to insert values to sqlite database\n",
    "\n",
    "with open(\"output.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "data_list = []\n",
    "for key, values in data.items():\n",
    "    data_list.append(tuple(values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "20a9c447-c766-4db0-949a-14458a82d55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating ans inserting values to the database from the json file\n",
    "\n",
    "import sqlite3 as sql\n",
    "\n",
    "conn = sql.connect(\"output.db\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"\"\"CREATE TABLE IF NOT EXISTS newoutput\n",
    "                    (url text PRIMARY KEY, title text, price text, img_src text, description text)\"\"\")\n",
    "\n",
    "cur.executemany(\"INSERT OR IGNORE INTO newoutput VALUES (?,?,?,?,?)\", data_list)\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "\n",
    "#Prints the database values\n",
    "\n",
    "# for row in cur.execute(\"\"\"SELECT * FROM newoutput\"\"\"):\n",
    "#     print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75ac44f-a692-4aa4-ba1a-b66bbc8e248d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
